# Reading 6 

The notion that an artifical intelligence that will hold powers beyond human capabability is an interesting phenomenon
to think about. It seems so matter of fact as well; they turned it into more of a question of when, not if. Its a scary thing
to think about. You don't know what that AI will do or what its goals will be. There are many theories, thoughts, and
preconcieved notions of what could happen that already surround this idea. I just hope that in future we will have a way to
prevent an AI from doing harm to people or it being able to freely do whatever it wants. Its interesting that we as a people
are so adament on creating something we fear. It comes back to the other reading about being fearful of the internet. Maybe we
will be the older generation that is fearful of everything AI but an AI will be everday life for our grandchildren. 

"How can you reason, how can you bargain, how can you understand how [a] machine is thinking when it's thinking in dimensions
you can't conceive of?" I think this is an interesting quote to pick out. Simply, we can't. We can't even begin imagine
comprehending a machine that has access to any knowledge of history and possible future events at its fingertips. The idea is
inherently flawed. Its like understanding the logic of a mentally insane person. If there isn't common sense to be found, you
wont find a common sense idea. Their logic is inherently flawed and so we can't understand them. We as a human race wont be
mentally ill, but we won't have access to all the information that an AI does and we won't be able to think through or read
though all that information. 

Artificial intelligence are like aliens, that we created. They will sit above us in the world that we established for them.
I liked this segment of the reading. I never really thought of AI as aliens. Though thats what they really will be. They will
be this foreign being to us, that we won't be able to fully comprehend. We can't even compete with them. It's ironic that we
created them.Bostrom brings up a metaphor that our intelligence, in relation to ASI, as analogous to what the intelligence of an ant feels 
to us. The goal of an AI is important. It will always choose the best possible path towards its goal. I guess the question from here
would be; Could an AI change its goal based on its own will? 


