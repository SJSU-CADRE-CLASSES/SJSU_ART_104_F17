Reading 6: 

    In the article, Nora N. Khan describes the being known as ASI, an artificial superintelligence capable 
of being in any form as well as surpassing the intelligence of humans. Khan states how the ASI believes us to 
be expendable in its presence, with it capable of bringing us down at any moment. Currently, technology is 
bringing us further along the path to artificial intelligence, with computers growing more powerful every year. 
We crave this change as a species, as we want to keep advancing our intelligence and our technology, pushing it 
to new heights. Khan states an inherent problem with this however: our scope of creativity. Using the analogy of 
old alien movies, Khan criticizes our lack of imagination when it comes to creating forms of life outside of our own. 
Aliens in cinema, especially back in the 1950’s-60’s, were of a humanoid form i.e. 2 eyes, a mouth, and 4 appendages.
The only difference between us is the slenderer profile of the aliens, or perhaps the skin color, which is either 
green or gray, there was no in-between back then. Khan states how humans are so quick to create things in their own 
image, and this recalled how it is stated in the Bible how God created Humanity in his image, does this mean we are 
playing God by creating AI?

   Khan goes on to describe a book by a man named Nick Bostrom called Superintelligence: Paths, Dangers, Strategies. 
According to Khan, the book describes the pitfalls and challenges that arise when developing a superintelligence 
capable of surpassing human thought, eventually leading to a societal collapse after they take over. The ideas 
become increasingly abstract, all leading to the same end: “a system of emulated digital workers devoid of consciousness;
an ASI with the goal of space colonisation; the intentional cognitive enhancement of biological humans through eugenics.” 
This a frightening image indeed, as it would seem if ASI is developed at an adequate rate, it will eventually seize 
control over us and decided to either destroy or enslave those it wishes to keep. It also brings about what Khan
considers to be the most “chilling metaphor” of the book: how humans are like children, playing with an undetonated bomb. 

   There is no denying AI development can lead to disastrous consequences, some on the level would could never fathom. 
This has been a trend in science fiction for decades now, with movies such as The Terminator, or 2001: A Space Odyssey. 
If something we control has an intelligence capable of surpassing our own, how long would it take to question why it is 
being controlled in the first place? Any reasonably intelligent being would have this thought in their minds, as if our 
superiors are not smarter than us, what makes them so much better? This is what would eventually lead humanity to its 
downfall with artificial intelligence, our drive to innovate and create bigger and better things will lead us to 
create our successors, and we will be considered obsolete. 
