To begin with, this article "Towards a Poetics
of Artificial Superintelligence" written by author Nora N. Khan, actually thrilled me in different ways, but it is a fascinating article indeed. Author Nora Khan is a well-known editor on the publications team at the American Academy of Arts and Sciences, Boston. In addition, she studies subjects in literature, cybernetics, games and electronic music through fiction, essays, and reviews, and has most recently been published in Rhizome, AVANT and DIS Magazine. She was processed through the Iowa Writers’ Workshop and Harvard. Writing this intriguing article shows how Nora Khan is credible as an author.

Khan started the article exceedingly in a way to make us imagine about having a machinic mind with unlimited cognitive power. She mentions about a world in which artificial superintelligence, or ASI, has emerged. Then she talks about AGI, also known as artificial general intelligence, one step before ASI, or simply an artificial intelligence (AI) that illustrates all characteristics of human intellect, is recognized. At this point to me, it started to get intense. I have heard of AI before, but ASI and AGI are new in my vocabulary. When the author stated that an AGI can do almost everything a human can that incorporates the way we learn, reason and even improve, things started to get serious because the only thing comes to my mind is either AI can take over the world or we control AI in way that we prevent something chaotic in the near future. Because AI existed years ago and will still and always be here. However, as the author said that AGI can "improve" means that it can evolve and if something wrong happens or AI turns out to act negatively then that could create a counteractive impact towards humanity. So, this was my point of view concerning AI/AGI/ASI. 

The author mentions that no one knows when AGI or ASI would originate, maybe it already is here but we have no idea when it would be out.According to Nora Khan, ASI will operate in a different manner where it will be difficult for mankind to understand; however, it will be friendly. A great figure that the author exemplified was that ASI also, known as Artificial Superintelligence, is like an alien. I totally agree with Khan because I do believe that there are extraterrestrials out there in the universe but we are not fully conscious of its existence. What also grabbed my attention was when she said that human cognition is only one species of intelligence, one with built-in impulses like understanding that color the way we see the world and limit what we are willing to do to accomplish our goals. But these biochemical impulses aren’t essential components of intelligence. They’re incidental software applications, installed by periods of evolution and culture. As mentioned in the article, AI is like a force of nature, like a star system or a hurricane. The concept of an intellect with such primordial, divine force sunk in deeper than any highly technical description of computational processing. So what Nora Khan is trying to say here is that not only does a concept of ASI like a hurricane cut to the centre of one’s fear receptors, it also makes the imaginings we have come up with, and continue to circulate such as adorable robot pets, discomfiting but ultimately human-like cyborgs, tears in rain, seem impossible and dangerously inept for what is to come. To me, this part was full of mystery because anthropomorphism comes to play a huge role in this. 

When we talk about a thing or animal as if it were human, you're anthropomorphizing it. The Easter Bunny, for example, is an anthropomorphized rabbit. People anthropomorphize all the time. According to Bostrom, Anthropomorphising superintelligence "encourages unfounded expectations" about the growth trajectory of a seed AI and about the "psychology, motivations, and capabilities of a mature superintelligence." What Bostrom was trying to say is that our species could rely on our capability to foretell, model and speculate well in the near future. Besides, Nora uses the word "Hurricane" as a metaphor that perfectly accommodated for how likely destructive an actual ASI could be. That scared me as soon as I read the word "destructive." Because back in my country, Mauritius, the houses are built with concrete and some wood, and if there is an active hurricane, our house will not be damaged unless it is a really strong and dangerous one. So, hurricanes can be in different ways. As stated in the article, if hurricanes seem like the end times, then the storms of other planets are "the stuff of hell" — the Great Red Spot of Jupiter is a hurricane-like storm, twice to three times the size of Earth. Thus, that is absolutely terrifying to hear. Moreover, mankind might conceive of a powerful, entirely accomplished ASI being much like this overpowering, massive and threatening force. A sophisticated ASI won’t apparently change its final goals due to human intervention. In fact, it would probably be indifferent to human action, intention, and existence. So, ASI could, in some situation, eventually turn againsts mankind despite the fact that we interrupt or try to alter the circumstances. 

Concerning architecture, the architecture of an ASI is like a natural one, as the intelligence can design spaces for an optimised existence, according to Bostrom. He followed by saying that an ASI creates emulations of artificial operators, who perform all the tasks that humans will be phased out of. To my understanding, ASI would be way smarter than human beings and whatever tasks they will give to their workers will undoubtedly be accomplished without any issues or complain because, we, as human, we get tired and sometimes we are either not good enough to perform specific tasks faster or complain about our work. On the other hand, the ASI architect discovers new neural abilities and makes insights that we have neither the quality nor speed processing ability to even access. Notwithstanding, I know that I, as a reader, have mostly mentioned the negative aspects of ASI however, the good viewpoints are here, ASI as a sovereign. Sovereign is a sumptuous word, magisterial, suggesting a self-sustaining, autonomous, cold judge, surveying the people of a channel. I like how khan gave the example of the drought and how ASI can come into help for people in need. Next is frontline, where the author said that it represents a "tension barrier," in which there is a limit where ASI can accelerate towards including a line of competition between rival superintelligent systems, between two ASIs. To me, I find this part really clever because there should be a limit/ a barrier where ASI does not go above to create havoc. 

Furthermore, I also read the swarm part in which Khan talks about the certainty of collective superintelligence. I never thought of anything like that in the virtual world but as the author mentions that swarm intelligence is a far more fitting description of an ASI’s neural network than any human analog, I was shocked. It is going beyond and way more beyond what I imagined. The swarm is arranged by sophisticated rules, with each individual mental event an expression of the mind’s overall mission. It can even approach something close to consciousness such as learning, language, and decision-making. So, to me, the question is that can a swarm expresses emotions then? since they are leading beyond to human expectation of what they can achieve. Can they achieve endless results or simply anything?
