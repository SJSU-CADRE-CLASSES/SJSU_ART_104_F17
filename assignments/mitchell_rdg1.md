## ART 104 - Reading 1
Trying to figure out what a 'lamprey' looks like can easily be done through a simple search on Google's image database. Type a word or a couple of words and the program will provide the user with a mass list of images found throughout the Internet. The user is not looking at the actual object, but instead still (sometimes animated) images of the particular object. Also, Google Images tends to show results that focus on key features that show a better representation of the search query. The user, nonetheless, is able to grasp an idea through these graphics and thus can be satisfied (or not).

Granata, in _[Processing/Lampreys](http://www.ctrl-z.net.au/articles/issue-6/granata-processing-lampreys/)_, discusses on the similarities between the parasitic characteristics of lampreys and the process behind processors. In her essay, the author talks about a program that feeds on external content, such as an image of a lamprey, in order to produce new contentâ€”a completely new image that has a few similar qualities to that of its 'host'.

This program and the results it produces are quite interesting. It reminds me of an experiment done by Peter Ashton called _[Sitting In Stagram](http://art.peteashton.com/sitting-in-stagram/)_, in which a self portrait image of the artist is uploaded to Instagram. The posted image is then saved and re-uploaded to Instagram. This process is repeated multiple times and the result is surprising and interesting. Since images are slightly compressed to save space, the image starts to lose some information and the result of the experiement looks drastically different from the original.

> :octocat: &nbsp; Mitchell Christ ([@nuotsu](https://github.com/nuotsu)) &nbsp;|&nbsp; Aug 30, 2017
