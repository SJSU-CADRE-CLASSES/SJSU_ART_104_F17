Subject 1: Stephanie(Set up)

  On March 23, 2016, Microsoft Corporation created and released a Artificial Intelligence chatbot known as ‘Tay’ onto Twitter. According 
to the creators, the AI was programmed to mimic the speech of a 19 year old girl with the “goal of becoming smarter by learning from the
conversations it encounters from real humans online.” Unfortunately, within the 24 hours the bot was released, Tay had begun to behave 
inappropriately making racist and sexist remarks, and harassing other twitter users. After 16 hours, the bot was taken down, with 
Microsoft blaming internet trolls for Tay’s behavior. However, it is shown that unlike Microsoft’s other AI Cortana, the creators of Tay 
did not code any appropriate responses to certains words pertaining to gender, race, religion, politics,etc. In turn, the creators 
unintentionally allowed the AI to become racist. The idea was to make the machine learn to respond like a human from the questions it 
was asked by humans. Tay did just that. It also begs the question; knowing the bot lacked countermeasures for certain words, does this 
mean that the large percentage of questions asked were racist or sexist in nature? Is the reason why Tay had failed because it was 
exploited by human curiosity on how far artificial intelligence can go, or simply because of hateful people online?

  In this day and age, forms of hate speech have become a very common occurence online especially in America. After the 2016 election of 
President Donald Trump, America has seen a significant political divide amongst it’s citizens- most notably seen from the openly typed 
opinions found on the internet. Right-wing individuals have begun to speak more freely of their conservative ideals; feeling a sense of 
safety against criticisms from a more liberal left-wing population. Even President Trump himself has partaken in expressing his personal 
thoughts, which are unfavorable to some, on the internet. Some of his thoughts scattered throughout Twitter have varied from racists 
insults to threatening nuclear war on North Korea. All the while, the news networks and politicians will speak of this without taking 
much action to stopping these behaviors. Why is this? With technology becoming so readily available and accessible to the masses, 
individuals such as President Trump and much of society look to online platforms to either escape from views differing from their own in 
the real world, or wish to further validate their ideals without feeling any consequences in front of faceless strangers. As a result, 
through social networking, history based searches, and the power of anonymity, humans continue to cultivate largely differing views that 
is consider to be the essence hate speech. Social media websites such as Twitter, Reddit, and Facebook have unfortunately become the 
main hubs for such individuals. However, the topic on hate speech has garnered more media attention recently in 2016 and 2017 due to the 
social and political views of the Alt-Right. 

  Coined by Richard Bertrand Spencer, the term Alt-Right, or the alternative right, is a loosely defined group of people that are made up of far right-wing extremists and white nationalists. These individuals reject the mainstream concepts of political correctness or social justice as these hinder their goals for the preservation of western civilization and white ethno-nationalism. While these group have existed for years spreading their message in “safe spaces” with websites such as Twitter, Breitbart News, and Reddit; they were not 
given much consideration from the general public. However, this changed during a far-right rally in Charlottesville, Virginia on August 
2017.  

  The Unite the Right rally was a scheduled rally in which it’s goal was to protest against the city’s controversial decision to remove 
America’s Civil War Confederate monuments and memorials from public spaces. During this rally, it was to oppose the removal of a statue 
of Robert E. Lee from Emancipation Park. Much of these protesters included neo-Nazis, Trump supporters, and individuals from the Alt-
Right; all of which chanted many racist and antisemitic remarks during the march. The main issue arose when protesters were faced with 
counter-protesters who were in favor of the removal of these statues. On August 12, a man belonging to a white-supremacist group drove 
his car into a crowd of counter-protesters resulting in 19 injuries and the death of a 32-year-old woman. In total, two day rally 
resulted in 35 casualties. Following the incident, many people have claimed what happened in Charlottesville an act of domestic 
terrorism and a hate crime, and opposition towards these groups rose especially on the web. Many websites began banning Alt-Right 
behavior on the basis of insinuating hate speech and promoting violence on the internet. As a result, the Alt-Right groups, feeling 
their views attacked and unwelcomed, wish to join together and form their own internet.

(Sinders, Caroline. "Microsoft's Tay is an Example of Bad Design – caroline sinders – Medium." Medium. March 24, 2016. Accessed November 
  15, 2017. https://medium.com/@ carolinesinders/microsoft-s-tay-is-an-example-of-bad-design-d4e65bb2569f.)

Subject 2: Norka (Technical)

  After the August 12 attacks in Charlottesville, many online platforms decided to take a stand and pull the plug on white supremacist 
websites, such as the Daily Stormer. The website had posted an article making derogatory comments about the woman who was killed while 
protesting the Unite the Right rally in Charlottesville, this prompted GoDaddy to boot the website off their servers. From there the 
Daily Stormer moved on to Google which also took a stand and banned the website. With little options left, they decided to move the 
website to a Russian domain name which lasted less than a day. Inevitably the Daily Stormer found it’s place in the dark web. Aside from 
being kicked from the internet, many other platforms such as service apps have kicked white supremacists from their services, such as: 
Uber, Airbnb, ApplePay, Discord, GoFundMe, and Paypal. 

  Domain names are regulated by ICANN, a multinational organization, “which hands off management of generic top-level domains(gTLDs) to 
organizations called registries. Registries can then sign contracts with ICANN-accredited registrars, which act as middlemen and sell 
domain names to the public.” The Daily Stormer is going to have to jump through some hoops because registrars have to be an established 
company that prove that they are technically capable and financially stable. “The Daily Stormer set up shop on the free and 
decentralized Tor network, operating on the so-called dark web.”

  With the Daily Stormer being hosted on the dark web the problem for them becomes accessibility for possible new members. Another 
significant setback for the Daily Stormer was when Cloudfare, a service that accelerates and secures websites, booted them. CloudFare 
secures websites from attacks such as Distributed Denial of Service (DDoS), an attack which makes an online service or website 
temporarily unavailable by overwhelming the website with traffic from many different sources. Currently the Daily Stormer is receiving 
DDoS protection from BitMitigate, a small startup company. There has been talk from the site contributors that they want to create their 
own alternative to Cloudflare as well as other parallel platforms. However with the amount of obstacles there are: domain names, 
security, etc. it might not work out in their favor. It seems that for the time being white supremacists will have to operate on the 
dark web and the few other websites that allow hate speech, such as; Gab and Hatreon. 

1.  Adi Robertson, "Why the alt-right can't build an alt-internet," The Verge (August 21, 2017), https://www.theverge.com/2017/8/21/16180614/charlottesville-daily-stormer-alt-right-internet-domain (Accessed November 7, 2017).

2.  Avi Selk, "A running list of companies that no longer want the Daily Stormer's business," The Washington Post (August 16, 2017), https://www.washingtonpost.com/news/the-switch/wp/2017/08/16/how-the-alt-right-got-kicked-offline-after-charlottesville-from-uber-to-google/ (Accessed November 7, 2017).

3.  Contessa Brewer, "Extreme right groups turn to 'shadow economy,'" CNBC (August 16,2017), https://www.cnbc.com/2017/08/16/extreme-right-groups-turn-to-shadow-economy.html (Accessed November 7, 2017)

Subject 3: Jennifer (Social Media Influence)

  Social Media refers to the collection of websites and applications that enable users to create and share content through electronic 
communication. These electronic communication technology include blogs, business networks, forums, photo and video sharing, and social 
gaming. The most common form of social media technology is social networking via online platforms such as Facebook, Twitter, LinkedIn, 
and Reddit. 

  Facebook is the most popular free social networking website to date and garners the most online traffic. According to a survey done by 
the Nielsen Group, internet users within the United States spend more time on facebook than any other site; approximately 84 percent of 
adolescents (ages 13 to 17) in America have a Facebook account. On Facebook, users can create profiles, upload photos, send messages and 
keep in touch with friends and family. People often use Facebook as their main tool for interaction with others, making these online 
platforms main hubs for communities of practice. 

  Communities of practice refers to groups that distinguish themselves through social organization in which people as a group learn 
together. Any individual can belong to one or multiple communities, and members of these communities are brought together through common 
goals, shared beliefs, and mutual engagement. They view and analyze events and experience through the same perspective. These like-
minded interactions between users create spaces known as Echo Chambers, rooms where only one particular ideology is reflected back and 
forth. Echo chambers have resulted in highly polarized discussions when users engage with other communities. Presently, the strong 
division between ideologies, such as left and right wing thinking, is unfortunately a consequence of technology and social media. 

  With technology constantly being developed and improved, the focus on digitalization and translating everything to an online space has 
become more widespread. Thanks to mobile devices such as smartphones and tablets, social networking is more accessible and influential. 
The convenience of mobile technology has encouraged an increasing number of individuals to use the internet as their main source of 
information gathering. Even businesses, news networks, and political outlets shave seen the benefits of having an online presence, thus 
they conduct a significant amount of work on the internet in order to strengthen their authority and reach a larger audience. However, 
this emphasis on digitalization has had major effects on people’s perception of reality, which is now based on belonging to a particular 
community of practice.

  Since information on the internet is in such abundance, sites like Facebook use an algorithm to filter and generate a selected feed 
that is believed suitable for each individual user based on their search history, liked content, and preferences. However, while users 
do get a personalized experience, they will not be provided or exposed to any objective or subjective information that is not in line 
with their beliefs, unless the they search it up for themselves. Information that is deemed inappropriate according the the website’s 
standards and own ideology is blocked, banned, or deleted so that such controversial or offensive material does not spread to other 
users. In this filter bubble, people’s perception of reality is unwillingly swayed and influenced. 

  Many news sites create filter bubbles by organizing discourse through the selection, emphasis, and exclusion of one or more aspects, a 
process known as framing. Framing defines what issue is relevant or not, and is one of the main reasons for the marginalization of 
groups and communities. Since the 2016 United States Presidential elections, Donald Trump's mistrust of traditional "mainstream 
media"has  changed the present media landscape. The emergence of “fake news” or “alternative news” has spawned sites such as  Breitbart, 
a news network that provides and spreads conservative and alt-right news, which have increased the support in the alt-right movement. 
One of the biggest features of Breitbart is the comment section for the articles which is uncensored and allows for freedom of speech.

  Main social media sites like Facebook and Twitter are often chastised by conservatives for being biased towards right-wing ideology. 
Many conservatives end up abandoning these popular online platforms in favor of other spaces, like Breitbart, where they are free to 
speak their opinions and listen to what they want to hear. As a result, however, the gap between liberal communities and conservative 
communities continues to widen as interaction between the two groups slowly diminishes over time.




1. Cadwalladr, C. "Robert Mercer: The Big Data Billionaire Waging War on Mainstream Media." Accessed November 14, 2017. https://www.theguardian.com/politics/2017/feb/26/robert-mercer-breitbart-war-on-media-steve-bannon-donald-trump-nigel-farage

2. Nguyen, Tien T., Pik-Mai Hui, F. Maxwell Harper, Loren Terveen, and Joseph A. Konstan. "Exploring the filter bubble." Proceedings of the 23rd international conference on World wide web - WWW 14, 2014. doi:10.1145/2566486.2568012.

3. Okeeffe, G. S., and K. Clarke-Pearson. "The Impact of Social Media on Children, Adolescents, and Families." Pediatrics 127, no. 4 (2011): 800-04. doi:10.1542/peds.2011-0054.



Subject 4. Lam

  The Rise and Fall of the Alt-Right
The Alternative Right, more commonly called the Alt-Right, is a group with members who subscribe to far-right ideologies concerning white identity. The group is among many that preach their extremist ideologies through various means, and in the more recent times they have concentrated their efforts on disseminating their ideas by employing internet based communication technologies. 

The incident at Charlottesville, where demonstrators and counter-demonstrators clashed with each other, has become a symbol of the challenges associated with freedom of speech in the country. This brings questions of regulation of free speech into the forefront, and raises questions about how untangling the First Amendment through technological means may be both necessary and challenging. At its root, the freedom of expression needs protection, even if it is considered hateful by some.  This is the only way to strengthen democracy and its legitimacy. 

Lapowsky believes that tech companies do not have to be placed under the net of First Amendment, since they are not the government and therefore free to police speech in the manner they deem fittest . Social media platforms such as Twitter and Facebook have already taken extremely aggressive stances to curb the activities of aggressive extremist groups such as ISIS, and the tools used by these companies can be extended to others as well. Instagram, for instance, have developed a filter that automatically deletes specific words from users’ feeds; and most interestingly, users can turn this feature on or off . So, users who are more likely to feel offended by certain types of speeches, can simply turn the option on, and filter all the materials that they find offensive. 

A combination of intuitive programming languages and algorithms can help identify trolling or offending patterns on the internet, and this can be used to eliminate offensive or inflammatory content from various websites that allow users to generate content. The Anaconda (Python 3.6) version is a dynamic programming language that has been made popular because of its high-level functionality and its ability to process natural language data using a Natural Language Toolkit. Using Anaconda, a Troll Identification Algorithm can be created, that is specifically aimed at targeting users and keywords that are misleading, offensive or associated with unnecessary or nonsensical information . The design of technologies and algorithms is aimed to improve overall identification of inflammatory content, while also allowing the communication technologies to expand without hurting the freedom of expression by over-censoring, and still preventing hate speech to become overbearing. 

There have been constant efforts to design abusive or inflammatory speech filters that seamlessly identify sensitive content and filter it out using  a token list. However, such methods are outdated, and relies on a human generated and populated blacklist for the filtration of content. Instead of this method, which is often deemed inefficient, advanced technologies such as Artificial Intelligence (AI) can be used to detect abusive content in social media. A number of methods that leverage the AI technologies have been identified, and these can be used to automate the data and content filtering process to make it more accurate and efficient. These include dataset balancing, which boosts detection of abusive content on social media; feature reduction, which aims at trimming the features of programs with large feature sets, to improve efficiency while still maintaining detection accuracy; use of generic structural features that can be used universally across datasets . 

References

Chen, Hao, Susan Mckeever, and Sarah Jane Delany. "Harnessing the Power of Text Mining for the Detection of Abusive Content in Social Media." In Advances in Computational Intelligence Systems, pp. 187-205. Springer International Publishing, 2017.

Lapowsky, Issie. Tech Companies Have the Tools to Confront White Supremacy. Wired, 2017. Accessed from https://www.wired.com/story/charlottesville-social-media-hate-speech-online/  

Snyder, Peter, Periwinkle Doerfler, Chris Kanich, and Damon McCoy. "Fifteen Minutes of Unwanted Fame: Detecting and Characterizing Doxing." strategies 10 (2017): 13.

Tayade, Pooja M., Shafi S. Shaikh, and S. N. Deshmukh. "To Discover Trolling Patterns in Social Media: Troll Filter." (2017).

Zhong, Haoti, Hao Li, Anna Cinzia Squicciarini, Sarah Michele Rajtmajer, Christopher Griffin, David J. Miller, and Cornelia Caragea. "Content-Driven Detection of Cyberbullying on the Instagram Social Network." In IJCAI, pp. 3952-3958. 2016.








